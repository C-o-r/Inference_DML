xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
par2[i] = result[1]
lcn2[i] = result[1]-(1.96*result[3]/sqrt(64))
ucn2[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
#change working directory
setwd("C:\\Users\\cor64\\Desktop\\Uni\\Erasmus\\Thesis\\DMLonGitHub-master\\")
#Lasso
#rm(list = ls())  # Clear everything out so we're starting clean
source("ML_Functions.R")
source("Moment_Functions.R")
options(warn=-1)
set.seed(1211);
cl   <- makeCluster(2, outfile="")
data(AJR)
#######
data=AJR
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
par2[i] = result[1]
lcn2[i] = result[1]-(1.96*result[3]/sqrt(64))
ucn2[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
############################################################################
#Lasso
#rm(list = ls())  # Clear everything out so we're starting clean
source("ML_Functions.R")
source("Moment_Functions.R")
options(warn=-1)
set.seed(1211);
cl   <- makeCluster(2, outfile="")
data(AJR)
#######
data=AJR
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
parl[i] = result[1]
lcnl[i] = result[1]-(1.96*result[3]/sqrt(64))
ucnl[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
resultsfinall = parl[2:6]
lcntl = lcnl[2:6]
ucntl = ucnl[2:6]
############################################################################
#Lasso
#rm(list = ls())  # Clear everything out so we're starting clean
source("ML_Functions.R")
source("Moment_Functions.R")
options(warn=-1)
set.seed(1211);
cl   <- makeCluster(2, outfile="")
data(AJR)
#######
data=AJR
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
parll[i] = result[1]
lcnl[i] = result[1]-(1.96*result[3]/sqrt(64))
ucnl[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
resultsfinall = parl[2:6]
lcnlll = lcnll[2:6]
ucnll = ucnll[2:6]
#rm(list = ls())  # Clear everything out so we're starting clean
source("ML_Functions.R")
source("Moment_Functions.R")
options(warn=-1)
set.seed(1211);
cl   <- makeCluster(2, outfile="")
data(AJR)
#######
data=AJR
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
parll[i] = result[1]
lcnll[i] = result[1]-(1.96*result[3]/sqrt(64))
ucnll[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
resultsfinall = parl[2:6]
lcnlll = lcnll[2:6]
ucnll = ucnll[2:6]
#Lasso
#rm(list = ls())  # Clear everything out so we're starting clean
source("ML_Functions.R")
source("Moment_Functions.R")
options(warn=-1)
set.seed(1211);
cl   <- makeCluster(2, outfile="")
data(AJR)
#######
data=AJR
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
parll[i] = result[1]
lcnll[i] = result[1]-(1.96*result[3]/sqrt(64))
ucnll[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
resultsfinall = parll[2:6]
lcnlll = lcnll[2:6]
ucnll = ucnll[2:6]
source('C:/Users/cor64/Desktop/Uni/Erasmus/Thesis/DMLonGitHub-master/complexity_B.R', echo=TRUE)
x <- c(2:6)
opar <- par(no.readonly=TRUE)
par(bg = "white")
plot(x, results$Par, type="b",
pch=1, col="red",
yaxt="n", lty=3,ylim=c(0, 0.5), ann=FALSE)
####change y lim to 1.5 end 30 for two grpahs!!!!
# not dobule: lines(x,results$Par , type="b", pch=22, col="red", lty=2)
lines(x,results$uc , type="b", pch=23, col="red", lty=2)
lines(x,results$lc , type="b", pch=23, col="red", lty=2)
lines(x,resultsfinalNNET , type="b", pch=25, col="blue", lty=2)
lines(x,lcn , type="b", pch=25, col="blue", lty=2)
lines(x,ucn , type="b", pch=25, col="blue", lty=2)
lines(x,resultsfinalNNETt , type="b", pch=23, col="brown", lty=2)
lines(x,lcnt , type="b", pch=23, col="brown", lty=2)
lines(x,ucnt , type="b", pch=23, col="brown", lty=2)
lines(x,resultsfinalfor , type="b", pch=23, col="green", lty=2)
lines(x,lcnt2 , type="b", pch=23, col="green", lty=2)
lines(x,ucnt2 , type="b", pch=23, col="green", lty=2)
lines(x,resultsfinall , type="b", pch=24, col="black", lty=2)
lines(x,lcnll  , type="b", pch=24, col="green", lty=2)
lines(x,ucnll , type="b", pch=24, col="green", lty=2)
axis(2,  col.axis="black", las=2)
legend("topleft", inset=.05, title="Algorithm type", c("IV","Nnet","Tree","Forrest","Lasso","Boosting"),
lty=c(1, 5), pch=c(21,25,23,24,25), col=c("red","blue","brown","green","black","red"))
#Algorithm estimators by interatively increasing covariates of ADJ
title("95% confidence intervals of parameter of interest",
xlab="amount of covariates",
ylab="95% confidence intervals of parameter of interest")
############################### Inputs ########################################
# Outcome Variable
y  <- "GDP" #:A? log?
# Treatment Variable
d  <- "Exprop"
# Instrument
z  <- "logMort"
x  <- "Latitude + Latitude2 + Africa +  Asia + Namer + Samer"       # use this for tree-based methods like forests and boosted trees
xl <- "(Latitude + Latitude2 + Africa +  Asia + Namer + Samer)^2"   # use this for rlasso etc.
parll = seq(0,8)
lcnll = seq(0,8)
ucnll = seq(0,8)
for (i in 2:6) {
if (i == 1) {}
else if (i==2) {
x  <- "Latitude + Latitude2 "       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2)^2"
}
else if (i==3) {      x  <- "Latitude + Latitude2 +Africa"       # use this for tree-based methods like forests and boosted trees
xla <- "(Latitude + Latitude2 + Africa )^2 "}
else if (i==4) {x  <- "Latitude + Latitude2 +Africa"
xla <- "(Latitude + Latitude2 + Africa +  Asia )^2" }
else if (i==5) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer  "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer)^2" }
else if (i==6) {x  <- "Latitude + Latitude2 +Africa +  Asia + Namer + Samer "
xla <- "(Latitude + Latitude2 + Africa +  Asia + Namer+Samer)^2"}
split        <- 2
RLasso       <- list(penalty = list(homoscedastic = FALSE, X.dependent.lambda =FALSE, lambda.start = NULL, c = 1.1), intercept = TRUE)
methods      <- c("RLasso")         # method names to be estimated
arguments    <- list( RLasso=RLasso)
r <- foreach(k = 1:split, .combine='rbind', .inorder=FALSE, .packages=c('MASS','randomForest','neuralnet','gbm', 'sandwich', 'hdm', 'nnet', 'rpart','glmnet')) %dopar% {
dml <- DoubleML(data=data, y=y, d=d, z=NULL, xx=x, xL=xl, methods=methods, DML="DML2", nfold=2, est="plinear", arguments=arguments, ensemble=ensemble, silent=FALSE, trim=c(0.01,0.99))
data.frame(t(dml[1,]), t(dml[2,]))
}
result           <- matrix(0,3, length(methods)+1)
colnames(result) <- cbind(t(methods), "best")
rownames(result) <- cbind("Median ATE", "se(median)",  "se")
result[1,]        <- colQuantiles(r[,1:(length(methods)+1)], probs=0.5)
result[2,]        <- colQuantiles(sqrt(r[,(length(methods)+2):ncol(r)]^2+(r[,1:(length(methods)+1)] - colQuantiles(r[,1:(length(methods)+1)], probs=0.5))^2), probs=0.5)
result[3,]        <- colQuantiles(r[,(length(methods)+2):ncol(r)], probs=0.5)
parll[i] = result[1]
lcnll[i] = result[1]-(1.96*result[3]/sqrt(64))
ucnll[i]=result[1]+(1.96*result[3]/sqrt(64))
#uc[i] = confint(fmfd, 'Exprop', level=0.95)[1]
#lc[i] = confint(fmfd, 'Exprop', level=0.95)[2]
}
source('C:/Users/cor64/Desktop/Uni/Erasmus/Thesis/DMLonGitHub-master/complexity_B.R', echo=TRUE)
par(bg = "white")
plot(x, results$Par, type="b",
pch=1, col="red",
yaxt="n", lty=3,ylim=c(0, 0.3), ann=FALSE)
####change y lim to 1.5 end 30 for two grpahs!!!!
# not dobule: lines(x,results$Par , type="b", pch=22, col="red", lty=2)
lines(x,results$uc , type="b", pch=23, col="red", lty=2)
lines(x,results$lc , type="b", pch=23, col="red", lty=2)
lines(x,resultsfinalNNET , type="b", pch=25, col="blue", lty=2)
lines(x,lcn , type="b", pch=25, col="blue", lty=2)
lines(x,ucn , type="b", pch=25, col="blue", lty=2)
lines(x,resultsfinalNNETt , type="b", pch=23, col="brown", lty=2)
lines(x,lcnt , type="b", pch=23, col="brown", lty=2)
lines(x,ucnt , type="b", pch=23, col="brown", lty=2)
lines(x,resultsfinalfor , type="b", pch=23, col="green", lty=2)
lines(x,lcnt2 , type="b", pch=23, col="green", lty=2)
lines(x,ucnt2 , type="b", pch=23, col="green", lty=2)
lines(x,resultsfinall , type="b", pch=24, col="black", lty=2)
lines(x,lcnll  , type="b", pch=24, col="black", lty=2)
lines(x,ucnll , type="b", pch=24, col="black", lty=2)
axis(2,  col.axis="black", las=2)
legend("topleft", inset=.05, title="Algorithm type", c("IV","Nnet","Tree","Forrest","Lasso","Boosting"),
lty=c(1, 5), pch=c(21,25,23,24,25), col=c("red","blue","brown","green","black","red"))
#Algorithm estimators by interatively increasing covariates of ADJ
title("95% confidence intervals of parameter of interest",
xlab="amount of covariates",
ylab="95% confidence intervals of parameter of interest")
x <- c(2:6)
opar <- par(no.readonly=TRUE)
par(bg = "white")
plot(x, results$Par, type="b",
pch=1, col="red",
yaxt="n", lty=3,ylim=c(0, 1), ann=FALSE)
####change y lim to 1.5 end 30 for two grpahs!!!!
# not dobule: lines(x,results$Par , type="b", pch=22, col="red", lty=2)
lines(x,results$uc , type="b", pch=23, col="red", lty=2)
lines(x,results$lc , type="b", pch=23, col="red", lty=2)
lines(x,resultsfinalNNET , type="b", pch=25, col="blue", lty=2)
lines(x,lcn , type="b", pch=25, col="blue", lty=2)
lines(x,ucn , type="b", pch=25, col="blue", lty=2)
lines(x,resultsfinalNNETt , type="b", pch=23, col="brown", lty=2)
lines(x,lcnt , type="b", pch=23, col="brown", lty=2)
lines(x,ucnt , type="b", pch=23, col="brown", lty=2)
lines(x,resultsfinalfor , type="b", pch=23, col="green", lty=2)
lines(x,lcnt2 , type="b", pch=23, col="green", lty=2)
lines(x,ucnt2 , type="b", pch=23, col="green", lty=2)
lines(x,resultsfinall , type="b", pch=24, col="black", lty=2)
lines(x,lcnll  , type="b", pch=24, col="black", lty=2)
lines(x,ucnll , type="b", pch=24, col="black", lty=2)
axis(2,  col.axis="black", las=2)
legend("topleft", inset=.05, title="Algorithm type", c("IV","Nnet","Tree","Forrest","Lasso","Boosting"),
lty=c(1, 5), pch=c(21,25,23,24,25), col=c("red","blue","brown","green","black","red"))
#Algorithm estimators by interatively increasing covariates of ADJ
title("95% confidence intervals of parameter of interest",
xlab="amount of covariates",
ylab="95% confidence intervals of parameter of interest")
source('C:/Users/cor64/Desktop/Uni/Erasmus/Thesis/DMLonGitHub-master/complexity_B.R', echo=TRUE)
par(bg = "white")
plot(x, results$Par, type="b",
pch=1, col="red",
yaxt="n", lty=3,ylim=c(0.2, 0.5), ann=FALSE)
####change y lim to 1.5 end 30 for two grpahs!!!!
# not dobule: lines(x,results$Par , type="b", pch=22, col="red", lty=2)
lines(x,results$uc , type="b", pch=23, col="red", lty=2)
lines(x,results$lc , type="b", pch=23, col="red", lty=2)
lines(x,resultsfinalNNET , type="b", pch=25, col="blue", lty=2)
lines(x,lcn , type="b", pch=25, col="blue", lty=2)
lines(x,ucn , type="b", pch=25, col="blue", lty=2)
lines(x,resultsfinalNNETt , type="b", pch=23, col="brown", lty=2)
lines(x,lcnt , type="b", pch=23, col="brown", lty=2)
lines(x,ucnt , type="b", pch=23, col="brown", lty=2)
lines(x,resultsfinalfor , type="b", pch=23, col="green", lty=2)
lines(x,lcnt2 , type="b", pch=23, col="green", lty=2)
lines(x,ucnt2 , type="b", pch=23, col="green", lty=2)
lines(x,resultsfinall , type="b", pch=24, col="black", lty=2)
lines(x,lcnll  , type="b", pch=24, col="black", lty=2)
lines(x,ucnll , type="b", pch=24, col="black", lty=2)
axis(2,  col.axis="black", las=2)
legend("topleft", inset=.05, title="Algorithm type", c("IV","Nnet","Tree","Forrest","Lasso","Boosting"),
lty=c(1, 5), pch=c(21,25,23,24,25), col=c("red","blue","brown","green","black","red"))
#Algorithm estimators by interatively increasing covariates of ADJ
title("95% confidence intervals of parameter of interest",
xlab="amount of covariates",
ylab="95% confidence intervals of parameter of interest")
source('C:/Users/cor64/Desktop/Uni/Erasmus/Thesis/DMLonGitHub-master/complexity_B.R', echo=TRUE)
x <- c(2:6)
opar <- par(no.readonly=TRUE)
par(bg = "white")
plot(x, results$Par, type="b",
pch=1, col="red",
yaxt="n", lty=3,ylim=c(0.2, 0.5), ann=FALSE)
####change y lim to 1.5 end 30 for two grpahs!!!!
# not dobule: lines(x,results$Par , type="b", pch=22, col="red", lty=2)
#lines(x,results$uc , type="b", pch=23, col="red", lty=2)
#lines(x,results$lc , type="b", pch=23, col="red", lty=2)
lines(x,resultsfinalNNET , type="b", pch=25, col="blue", lty=2)
#lines(x,lcn , type="b", pch=25, col="blue", lty=2)
#lines(x,ucn , type="b", pch=25, col="blue", lty=2)
lines(x,resultsfinalNNETt , type="b", pch=23, col="brown", lty=2)
#lines(x,lcnt , type="b", pch=23, col="brown", lty=2)
#lines(x,ucnt , type="b", pch=23, col="brown", lty=2)
lines(x,resultsfinalfor , type="b", pch=23, col="green", lty=2)
#lines(x,lcnt2 , type="b", pch=23, col="green", lty=2)
#lines(x,ucnt2 , type="b", pch=23, col="green", lty=2)
lines(x,resultsfinall , type="b", pch=24, col="black", lty=2)
#lines(x,lcnll  , type="b", pch=24, col="black", lty=2)
#lines(x,ucnll , type="b", pch=24, col="black", lty=2)
axis(2,  col.axis="black", las=2)
legend("topleft", inset=.05, title="Algorithm type", c("IV","Nnet","Tree","Forrest","Lasso","Boosting"),
lty=c(1, 5), pch=c(21,25,23,24,25), col=c("red","blue","brown","green","black","red"))
#Algorithm estimators by interatively increasing covariates of ADJ
title("95% confidence intervals of parameter of interest",
xlab="amount of covariates",
ylab="95% confidence intervals of parameter of interest")
source('C:/Users/cor64/Desktop/Uni/Erasmus/Thesis/DMLonGitHub-master/complexity_B.R', echo=TRUE)
